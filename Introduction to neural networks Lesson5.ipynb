{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Введение в искусственные нейронные сети\n",
    "# Урок 5. Рекуррентные нейронные сети"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Практика"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте попробуем сделать простую реккурентную нейронную сеть, которая будет учиться складывать числа. Для этих целей мы не будем пользоваться фреймворками для Deep Learning, чтобы посмотреть как она работает внутри.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:[3.45638663]\n",
      "Pred:[0 0 0 0 0 0 0 1]\n",
      "True:[0 1 0 0 0 1 0 1]\n",
      "9 + 60 = 1\n",
      "------------\n",
      "Error:[3.63389116]\n",
      "Pred:[1 1 1 1 1 1 1 1]\n",
      "True:[0 0 1 1 1 1 1 1]\n",
      "28 + 35 = 255\n",
      "------------\n",
      "Error:[3.91366595]\n",
      "Pred:[0 1 0 0 1 0 0 0]\n",
      "True:[1 0 1 0 0 0 0 0]\n",
      "116 + 44 = 72\n",
      "------------\n",
      "Error:[3.72191702]\n",
      "Pred:[1 1 0 1 1 1 1 1]\n",
      "True:[0 1 0 0 1 1 0 1]\n",
      "4 + 73 = 223\n",
      "------------\n",
      "Error:[3.5852713]\n",
      "Pred:[0 0 0 0 1 0 0 0]\n",
      "True:[0 1 0 1 0 0 1 0]\n",
      "71 + 11 = 8\n",
      "------------\n",
      "Error:[2.53352328]\n",
      "Pred:[1 0 1 0 0 0 1 0]\n",
      "True:[1 1 0 0 0 0 1 0]\n",
      "81 + 113 = 162\n",
      "------------\n",
      "Error:[0.57691441]\n",
      "Pred:[0 1 0 1 0 0 0 1]\n",
      "True:[0 1 0 1 0 0 0 1]\n",
      "81 + 0 = 81\n",
      "------------\n",
      "Error:[1.42589952]\n",
      "Pred:[1 0 0 0 0 0 0 1]\n",
      "True:[1 0 0 0 0 0 0 1]\n",
      "4 + 125 = 129\n",
      "------------\n",
      "Error:[0.47477457]\n",
      "Pred:[0 0 1 1 1 0 0 0]\n",
      "True:[0 0 1 1 1 0 0 0]\n",
      "39 + 17 = 56\n",
      "------------\n",
      "Error:[0.21595037]\n",
      "Pred:[0 0 0 0 1 1 1 0]\n",
      "True:[0 0 0 0 1 1 1 0]\n",
      "11 + 3 = 14\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "# впервую очередь подключим numpy и библиотеку copy, которая понадобиться, чтобы сделать deepcopy ряда элементов\n",
    "\n",
    "import copy, numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "# вычислим сигмоиду\n",
    "def sigmoid(x):\n",
    "    output = 1/(1+np.exp(-x))\n",
    "    return output\n",
    "\n",
    "# конвертируем значение функции сигмоиды в ее производную. \n",
    "def sigmoid_output_to_derivative(output):\n",
    "    return output*(1-output)\n",
    "\n",
    "# генерация тренировочного датасета\n",
    "int2binary = {}\n",
    "binary_dim = 8\n",
    "\n",
    "largest_number = pow(2,binary_dim)\n",
    "binary = np.unpackbits(np.array([list(range(largest_number))],dtype=np.uint8).T,axis=1)\n",
    "for i in range(largest_number):\n",
    "    int2binary[i] = binary[i]\n",
    "\n",
    "# входные переменные\n",
    "alpha = 0.1\n",
    "input_dim = 2\n",
    "hidden_dim = 16\n",
    "output_dim = 1\n",
    "\n",
    "\n",
    "# инициализация весов нейронной сети\n",
    "synapse_0 = 2*np.random.random((input_dim,hidden_dim)) - 1\n",
    "synapse_1 = 2*np.random.random((hidden_dim,output_dim)) - 1\n",
    "synapse_h = 2*np.random.random((hidden_dim,hidden_dim)) - 1\n",
    "\n",
    "synapse_0_update = np.zeros_like(synapse_0)\n",
    "synapse_1_update = np.zeros_like(synapse_1)\n",
    "synapse_h_update = np.zeros_like(synapse_h)\n",
    "\n",
    "# тренировочная логика\n",
    "for j in range(10000):\n",
    "    \n",
    "    # генерация простой проблемы сложения (a + b = c)\n",
    "    a_int = np.random.randint(largest_number/2) # int version\n",
    "    a = int2binary[a_int] # бинарное кодирование\n",
    "\n",
    "    b_int = np.random.randint(largest_number/2) # int version\n",
    "    b = int2binary[b_int] # бинарное кодирование\n",
    "\n",
    "    # правильный ответ\n",
    "    c_int = a_int + b_int\n",
    "    c = int2binary[c_int]\n",
    "    \n",
    "    # место где мы располагаем наши лучше результаты (бинарно закодированные)\n",
    "    d = np.zeros_like(c)\n",
    "\n",
    "    overallError = 0\n",
    "    \n",
    "    layer_2_deltas = list()\n",
    "    layer_1_values = list()\n",
    "    layer_1_values.append(np.zeros(hidden_dim))\n",
    "    \n",
    "    # движение вдоль позиций бинарной кодировки\n",
    "    for position in range(binary_dim):\n",
    "        \n",
    "        # генерация input и output\n",
    "        X = np.array([[a[binary_dim - position - 1],b[binary_dim - position - 1]]])\n",
    "        y = np.array([[c[binary_dim - position - 1]]]).T\n",
    "\n",
    "        # внутренний слой (input ~+ предыдущий внутренний)\n",
    "        layer_1 = sigmoid(np.dot(X,synapse_0) + np.dot(layer_1_values[-1],synapse_h))\n",
    "\n",
    "        # output layer (новое бинарное представление)\n",
    "        layer_2 = sigmoid(np.dot(layer_1,synapse_1))\n",
    "\n",
    "        # проверка упустили ли мы что-то и если да, то как много \n",
    "        layer_2_error = y - layer_2\n",
    "        layer_2_deltas.append((layer_2_error)*sigmoid_output_to_derivative(layer_2))\n",
    "        overallError += np.abs(layer_2_error[0])\n",
    "    \n",
    "        # декодируем оценку чтобы мы могли ее вывести на экран\n",
    "        d[binary_dim - position - 1] = np.round(layer_2[0][0])\n",
    "        \n",
    "        # сохраняем внутренний слой, чтобы мы могли его использовать в след. timestep\n",
    "        layer_1_values.append(copy.deepcopy(layer_1))\n",
    "    \n",
    "    future_layer_1_delta = np.zeros(hidden_dim)\n",
    "    \n",
    "    for position in range(binary_dim):\n",
    "        \n",
    "        X = np.array([[a[position],b[position]]])\n",
    "        layer_1 = layer_1_values[-position-1]\n",
    "        prev_layer_1 = layer_1_values[-position-2]\n",
    "        \n",
    "        # величина ошибки в output layer\n",
    "        layer_2_delta = layer_2_deltas[-position-1]\n",
    "        # величина ошибки в hidden layer\n",
    "        layer_1_delta = (future_layer_1_delta.dot(synapse_h.T) + layer_2_delta.dot(synapse_1.T)) * sigmoid_output_to_derivative(layer_1)\n",
    "\n",
    "        # обновление всех весов и пробуем заново\n",
    "        synapse_1_update += np.atleast_2d(layer_1).T.dot(layer_2_delta)\n",
    "        synapse_h_update += np.atleast_2d(prev_layer_1).T.dot(layer_1_delta)\n",
    "        synapse_0_update += X.T.dot(layer_1_delta)\n",
    "        \n",
    "        future_layer_1_delta = layer_1_delta\n",
    "    \n",
    "\n",
    "    synapse_0 += synapse_0_update * alpha\n",
    "    synapse_1 += synapse_1_update * alpha\n",
    "    synapse_h += synapse_h_update * alpha    \n",
    "\n",
    "    synapse_0_update *= 0\n",
    "    synapse_1_update *= 0\n",
    "    synapse_h_update *= 0\n",
    "    \n",
    "    # вывод на экран процесса обучения\n",
    "    if(j % 1000 == 0):\n",
    "        print(\"Error:\" + str(overallError))\n",
    "        print(\"Pred:\" + str(d))\n",
    "        print(\"True:\" + str(c))\n",
    "        out = 0\n",
    "        for index,x in enumerate(reversed(d)):\n",
    "            out += x*pow(2,index)\n",
    "        print(str(a_int) + \" + \" + str(b_int) + \" = \" + str(out))\n",
    "        print(\"------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь давайте попробуем с помощью Keras построить LSTM нейронную сеть для оценки настроений отзвывов на IMD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данный датасет слишком мал, чтобы преимущества LSTM проявились, однако в учебных целях он подойдет.\n",
    "\n",
    "В тренировке рекуррентных нейронных сетей важную роль играет размер batch, но еще большую роль играет выбор функций loss и optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загрузка данных...\n",
      "25000 тренировочные последовательности\n",
      "25000 тестовые последовательности\n",
      "Pad последовательности (примеров в x единицу времени)\n",
      "x_train shape: (25000, 80)\n",
      "x_test shape: (25000, 80)\n",
      "Построение модели...\n",
      "Процесс обучения...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\radja\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 66s 3ms/step - loss: 0.4613 - accuracy: 0.7785 - val_loss: 0.3686 - val_accuracy: 0.8375\n",
      "25000/25000 [==============================] - 12s 471us/step\n",
      "Результат при тестировании: 0.3685916298389435\n",
      "Тестовая точность: 0.8375200033187866\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.datasets import imdb\n",
    "\n",
    "max_features = 20000\n",
    "\n",
    "# обрезание текстов после данного количества слов (среди top max_features наиболее используемые слова)\n",
    "maxlen = 80\n",
    "batch_size = 80 # увеличьте значение для ускорения обучения\n",
    "\n",
    "print('Загрузка данных...')\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "\n",
    "# здесь попытаюсь поменять соотношение тестовых и тренировочных данных (было 50 на 50 стало 20 на 80) \n",
    "\n",
    "# data = np.concatenate((x_train, x_test), axis=0)\n",
    "# targets = np.concatenate((y_train, y_test), axis=0) \n",
    "# print(data.shape, targets.shape)\n",
    "\n",
    "# x_test = data[:10000]\n",
    "# y_test = targets[:10000]\n",
    "# x_train = data[10000:]\n",
    "# y_train = targets[10000:]\n",
    "# print(x_test.shape, y_test.shape, x_train.shape, y_train.shape)\n",
    "\n",
    "print(len(x_train), 'тренировочные последовательности')\n",
    "print(len(x_test), 'тестовые последовательности')\n",
    "\n",
    "\n",
    "\n",
    "print('Pad последовательности (примеров в x единицу времени)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "\n",
    "print('Построение модели...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# стоит попробовать использовать другие оптимайзер и другие конфигурации оптимайзеров \n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Процесс обучения...')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=1, # увеличьте при необходимости\n",
    "          validation_data=(x_test, y_test))\n",
    "score, acc = model.evaluate(x_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Результат при тестировании:', score)\n",
    "print('Тестовая точность:', acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### По умолчанию   - Тестовая точность: 0.82\n",
    "##### Поменял функцию активации на softmax - Тестовая точность: 0.5\n",
    "##### Увеличил количество нейронов в LSTM до 512  -  Тестовая точность: 0.84\n",
    "##### Уменьшил количество нейронов в LSTM до 64   -  Тестовая точность: 0.84\n",
    "##### Поменял соотношение тестовых и тренировочных данных (было 50 на 50 стало 20 на 80)  -  Тестовая точность: 0.84\n",
    "##### Увеличил batch_size до 80   -  Тестовая точность: 0.84\n",
    "##### Увеличил batch_size до 128   -  Тестовая точность: 0.82\n",
    "##### При смене функции потерь на mean_squared_error  не заметил изменений\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте также посмотрим пример в которм будет использоваться другой класс задач - генерация текста на основе тренировочного текста. В задачу нейросети будет входить обучившись на тексте Алиса в стране чудес и начать генерировать текст похожий на тот, что можно встретить в этой книге. Также в этом примере будет использоваться GRU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Итерация #: 0\n",
      "Epoch 1/3\n",
      "407113/407113 [==============================] - 49s 121us/step - loss: 2.5494\n",
      "Epoch 2/3\n",
      "407113/407113 [==============================] - 49s 120us/step - loss: 2.0846\n",
      "Epoch 3/3\n",
      "407113/407113 [==============================] - 49s 120us/step - loss: 1.9083\n",
      "Генерация из посева: и мост. Ги\n",
      "и мост. Гирании в постенники и поставления и поставления и поставления и поставления и поставления и поставления и поставления и поставления и поставления и поставления и поставления и поставления и поставления==================================================\n",
      "Итерация #: 1\n",
      "Epoch 1/3\n",
      "407113/407113 [==============================] - 49s 119us/step - loss: 1.7947\n",
      "Epoch 2/3\n",
      "407113/407113 [==============================] - 49s 119us/step - loss: 1.7145\n",
      "Epoch 3/3\n",
      "407113/407113 [==============================] - 49s 119us/step - loss: 1.6552\n",
      "Генерация из посева: акже и сво\n",
      "акже и своим политической держава с не заглавить собой в свои войска и политической держава с не заглавить собой в свои войска и политической держава с не заглавить собой в свои войска и политической держава с ==================================================\n",
      "Итерация #: 2\n",
      "Epoch 1/3\n",
      "407113/407113 [==============================] - 48s 119us/step - loss: 1.6088\n",
      "Epoch 2/3\n",
      "407113/407113 [==============================] - 48s 119us/step - loss: 1.5723\n",
      "Epoch 3/3\n",
      "407113/407113 [==============================] - 48s 119us/step - loss: 1.5412\n",
      "Генерация из посева: 120 км) от\n",
      "120 км) от исена политической державы и произошел от поход против не возможность после страты после страты после страты после страты после страты после страты после страты после страты после страты после страты==================================================\n",
      "Итерация #: 3\n",
      "Epoch 1/3\n",
      "407113/407113 [==============================] - 48s 119us/step - loss: 1.5160\n",
      "Epoch 2/3\n",
      "407113/407113 [==============================] - 48s 119us/step - loss: 1.4952\n",
      "Epoch 3/3\n",
      "407113/407113 [==============================] - 49s 119us/step - loss: 1.4773\n",
      "Генерация из посева: ия Алексан\n",
      "ия Александра с трудом политической державы на стены принял в собой воспользовал своих приближения своих приближения своих приближения своих приближения своих приближения своих приближения своих приближения сво==================================================\n",
      "Итерация #: 4\n",
      "Epoch 1/3\n",
      "407113/407113 [==============================] - 49s 119us/step - loss: 1.4609\n",
      "Epoch 2/3\n",
      "407113/407113 [==============================] - 48s 119us/step - loss: 1.4462\n",
      "Epoch 3/3\n",
      "407113/407113 [==============================] - 49s 119us/step - loss: 1.4322\n",
      "Генерация из посева: олжения по\n",
      "олжения политические политические политические политические политические политические политические политические политические политические политические политические политические политические политические политич==================================================\n",
      "Итерация #: 5\n",
      "Epoch 1/3\n",
      "407113/407113 [==============================] - 49s 119us/step - loss: 1.4203\n",
      "Epoch 2/3\n",
      "407113/407113 [==============================] - 48s 119us/step - loss: 1.4087\n",
      "Epoch 3/3\n",
      "407113/407113 [==============================] - 48s 119us/step - loss: 1.3983\n",
      "Генерация из посева: тнейших пе\n",
      "тнейших перед на подобные поддержавший в страну и политические полиса от своей политические полиса от своей политические полиса от своей политические полиса от своей политические полиса от своей политические по==================================================\n",
      "Итерация #: 6\n",
      "Epoch 1/3\n",
      "407113/407113 [==============================] - 48s 119us/step - loss: 1.3877\n",
      "Epoch 2/3\n",
      "407113/407113 [==============================] - 48s 118us/step - loss: 1.3784\n",
      "Epoch 3/3\n",
      "407113/407113 [==============================] - 48s 118us/step - loss: 1.3704\n",
      "Генерация из посева: ной крепос\n",
      "ной крепость и последний совершил возвращение в свое время своих приближенных в созданного постоянно положение своих приближенных в созданного постоянно положение своих приближенных в созданного постоянно полож==================================================\n",
      "Итерация #: 7\n",
      "Epoch 1/3\n",
      "407113/407113 [==============================] - 48s 118us/step - loss: 1.3630\n",
      "Epoch 2/3\n",
      "407113/407113 [==============================] - 49s 120us/step - loss: 1.3555\n",
      "Epoch 3/3\n",
      "407113/407113 [==============================] - 49s 120us/step - loss: 1.3489\n",
      "Генерация из посева: юза был со\n",
      "юза был создавает совершил свои войска и поддерживали, что он подобного врагами и после смерти Александра и подобные поддерживали, что он подобного врагами и после смерти Александра и подобные поддерживали, что==================================================\n",
      "Итерация #: 8\n",
      "Epoch 1/3\n",
      "407113/407113 [==============================] - 49s 120us/step - loss: 1.3423\n",
      "Epoch 2/3\n",
      "407113/407113 [==============================] - 49s 120us/step - loss: 1.3361\n",
      "Epoch 3/3\n",
      "407113/407113 [==============================] - 49s 120us/step - loss: 1.3305\n",
      "Генерация из посева: атными муж\n",
      "атными мужей, однако сопротивление в своей стороны и последний в настроения с ним в свою войска на свои войска на свои войска на свои войска на свои войска на свои войска на свои войска на свои войска на свои в==================================================\n",
      "Итерация #: 9\n",
      "Epoch 1/3\n",
      "407113/407113 [==============================] - 49s 120us/step - loss: 1.3243\n",
      "Epoch 2/3\n",
      "407113/407113 [==============================] - 49s 120us/step - loss: 1.3190\n",
      "Epoch 3/3\n",
      "407113/407113 [==============================] - 49s 119us/step - loss: 1.3140\n",
      "Генерация из посева: я слеза ст\n",
      "я слеза страны и от политических поставленные политических поставленные политических поставленные политических поставленные политических поставленные политических поставленные политических поставленные политиче==================================================\n",
      "Итерация #: 10\n",
      "Epoch 1/3\n",
      "407113/407113 [==============================] - 48s 119us/step - loss: 1.3083\n",
      "Epoch 2/3\n",
      "407113/407113 [==============================] - 48s 119us/step - loss: 1.3034\n",
      "Epoch 3/3\n",
      "407113/407113 [==============================] - ETA: 0s - loss: 1.299 - 49s 119us/step - loss: 1.2994\n",
      "Генерация из посева: вив после \n",
      "вив после того, как послужили самого Александр приказал возможность составлявших в советав и политических приближенными при всей воспользоваться в свою власть на свои войска на свои войска на свои войска на сво==================================================\n",
      "Итерация #: 11\n",
      "Epoch 1/3\n",
      "407113/407113 [==============================] - 49s 120us/step - loss: 1.2952\n",
      "Epoch 2/3\n",
      "407113/407113 [==============================] - 49s 120us/step - loss: 1.2911\n",
      "Epoch 3/3\n",
      "407113/407113 [==============================] - 49s 120us/step - loss: 1.2875\n",
      "Генерация из посева: внимания. \n",
      "внимания. В разгар был вынужден отправил с ним в свою власть на стороне военных и постановление в город был вынужден отправил с ним в свою власть на стороне военных и постановление в город был вынужден отправил==================================================\n",
      "Итерация #: 12\n",
      "Epoch 1/3\n",
      "407113/407113 [==============================] - 49s 120us/step - loss: 1.2836\n",
      "Epoch 2/3\n",
      "407113/407113 [==============================] - 49s 120us/step - loss: 1.2798\n",
      "Epoch 3/3\n",
      "407113/407113 [==============================] - 49s 119us/step - loss: 1.2760\n",
      "Генерация из посева: епость и п\n",
      "епость и после смерти своих своих приближенных в солдаты последовательно продолжил свои корабли и приступил в политической и последовательно продолжил свои корабли и приступил в политической и последовательно п==================================================\n",
      "Итерация #: 13\n",
      "Epoch 1/3\n",
      "407113/407113 [==============================] - 49s 119us/step - loss: 1.2729\n",
      "Epoch 2/3\n",
      "407113/407113 [==============================] - 48s 119us/step - loss: 1.2696\n",
      "Epoch 3/3\n",
      "407113/407113 [==============================] - 48s 119us/step - loss: 1.2660\n",
      "Генерация из посева: ну Филона,\n",
      "ну Филона, и после от того чтобы после смерти событий и другие против персидской армии из своей стороны в свое время полисов относительно получил свое положение в свое время полисов относительно получил свое по==================================================\n",
      "Итерация #: 14\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "407113/407113 [==============================] - 48s 119us/step - loss: 1.2632\n",
      "Epoch 2/3\n",
      "407113/407113 [==============================] - 48s 119us/step - loss: 1.2605\n",
      "Epoch 3/3\n",
      "407113/407113 [==============================] - 48s 119us/step - loss: 1.2573\n",
      "Генерация из посева: а даже тех\n",
      "а даже тех, кто по приказу Александр приказал возвращении из своих приближенных войска на себе после того, как и в свое время по приказу Александр приказал возвращении из своих приближенных войска на себе после==================================================\n",
      "Итерация #: 15\n",
      "Epoch 1/3\n",
      "407113/407113 [==============================] - 49s 119us/step - loss: 1.2551\n",
      "Epoch 2/3\n",
      "407113/407113 [==============================] - 49s 119us/step - loss: 1.2520\n",
      "Epoch 3/3\n",
      "407113/407113 [==============================] - 49s 119us/step - loss: 1.2495\n",
      "Генерация из посева: зованный м\n",
      "зованный македонского царя Александр приказал собой разумеется, по представлениями и ответе после того, как он после в представлениями и ответе после того, как он после в представлениями и ответе после того, ка==================================================\n",
      "Итерация #: 16\n",
      "Epoch 1/3\n",
      "407113/407113 [==============================] - 48s 119us/step - loss: 1.2464\n",
      "Epoch 2/3\n",
      "407113/407113 [==============================] - 48s 119us/step - loss: 1.2440\n",
      "Epoch 3/3\n",
      "407113/407113 [==============================] - 48s 119us/step - loss: 1.2416\n",
      "Генерация из посева: ми в Египт\n",
      "ми в Египте, которые прибыли в похода с последний по предание в своей стороны подошел к Александр приказал собой поддержкой отношения с ним в конце концов под командованием Александр приказал собой поддержкой о==================================================\n",
      "Итерация #: 17\n",
      "Epoch 1/3\n",
      "407113/407113 [==============================] - 48s 118us/step - loss: 1.2392\n",
      "Epoch 2/3\n",
      "407113/407113 [==============================] - 49s 119us/step - loss: 1.2371\n",
      "Epoch 3/3\n",
      "407113/407113 [==============================] - 49s 119us/step - loss: 1.2352\n",
      "Генерация из посева: ласия посл\n",
      "ласия последний последовательно при всей в своих солдат на случае последний последовательно при всей в своих солдат на случае последний последовательно при всей в своих солдат на случае последний последовательн==================================================\n",
      "Итерация #: 18\n",
      "Epoch 1/3\n",
      "407113/407113 [==============================] - 49s 120us/step - loss: 1.2328\n",
      "Epoch 2/3\n",
      "407113/407113 [==============================] - 49s 119us/step - loss: 1.2305\n",
      "Epoch 3/3\n",
      "407113/407113 [==============================] - 49s 120us/step - loss: 1.2283\n",
      "Генерация из посева:  них Алекс\n",
      " них Александр поставил свое время подчеркивает собой получил свое противников и подозрительным приближенных противников и подозрительным приближенных противников и подозрительным приближенных противников и под==================================================\n",
      "Итерация #: 19\n",
      "Epoch 1/3\n",
      "407113/407113 [==============================] - 49s 120us/step - loss: 1.2268\n",
      "Epoch 2/3\n",
      "407113/407113 [==============================] - 49s 120us/step - loss: 1.2243\n",
      "Epoch 3/3\n",
      "407113/407113 [==============================] - 49s 119us/step - loss: 1.2224\n",
      "Генерация из посева: ния фланго\n",
      "ния фланговались в состанейся после всевозвадными и от получил свое правительство на свое исключительные политической жизни Александр послал в стремится в получило в сочинения Александр послал в стремится в пол==================================================\n",
      "Итерация #: 20\n",
      "Epoch 1/3\n",
      "407113/407113 [==============================] - 49s 119us/step - loss: 1.2199\n",
      "Epoch 2/3\n",
      "407113/407113 [==============================] - 49s 119us/step - loss: 1.2182\n",
      "Epoch 3/3\n",
      "407113/407113 [==============================] - 49s 119us/step - loss: 1.2166\n",
      "Генерация из посева: но. Упомин\n",
      "но. Упоминавшийся при нем возможность по представлял собой устраивали в своем не мог оттуда в своем не мог оттуда в своем не мог оттуда в своем не мог оттуда в своем не мог оттуда в своем не мог оттуда в своем ==================================================\n",
      "Итерация #: 21\n",
      "Epoch 1/3\n",
      "407113/407113 [==============================] - 49s 119us/step - loss: 1.2148\n",
      "Epoch 2/3\n",
      "407113/407113 [==============================] - 49s 119us/step - loss: 1.2131\n",
      "Epoch 3/3\n",
      "407113/407113 [==============================] - 49s 120us/step - loss: 1.2111\n",
      "Генерация из посева: ния“) виде\n",
      "ния“) видел в своем не остановился в своем не остановился в своем не остановился в своем не остановился в своем не остановился в своем не остановился в своем не остановился в своем не остановился в своем не ост==================================================\n",
      "Итерация #: 22\n",
      "Epoch 1/3\n",
      "407113/407113 [==============================] - 49s 119us/step - loss: 1.2093\n",
      "Epoch 2/3\n",
      "407113/407113 [==============================] - 49s 119us/step - loss: 1.2078\n",
      "Epoch 3/3\n",
      "407113/407113 [==============================] - 49s 119us/step - loss: 1.2064\n",
      "Генерация из посева: т ли кто-н\n",
      "т ли кто-нибудь сильное воспользоваться в страны и отдельных присладное сопротивление в соответственно против общего врага это событие в солдатам поддержку своих приближенных присладное сопротивление в соответс==================================================\n",
      "Итерация #: 23\n",
      "Epoch 1/3\n",
      "407113/407113 [==============================] - 48s 119us/step - loss: 1.2045\n",
      "Epoch 2/3\n",
      "407113/407113 [==============================] - 48s 119us/step - loss: 1.2031\n",
      "Epoch 3/3\n",
      "407113/407113 [==============================] - 48s 119us/step - loss: 1.2019\n",
      "Генерация из посева: арх, Алекс\n",
      "арх, Алекс, 17]. Последнему образом, на котором последовательно простоочил их привел с ними и от получали с ним в город против персидский флот в своем не мог относитства и приступил в предание в своем не мог от==================================================\n",
      "Итерация #: 24\n",
      "Epoch 1/3\n",
      "407113/407113 [==============================] - 48s 119us/step - loss: 1.2005\n",
      "Epoch 2/3\n",
      "407113/407113 [==============================] - 48s 119us/step - loss: 1.1990\n",
      "Epoch 3/3\n",
      "407113/407113 [==============================] - 48s 119us/step - loss: 1.1970\n",
      "Генерация из посева: ях; ведь и\n",
      "ях; ведь и в политической жизни Александр поставил противоречив и построить в кормушком под командованием Александр поставил противоречив и построить в кормушком под командованием Александр поставил противоречи\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers.recurrent import SimpleRNN, LSTM, GRU\n",
    "from keras.models import Sequential\n",
    "\n",
    "\n",
    "# построчное чтение из примера с текстом \n",
    "# with open(\"alice_in_wonderland.txt\", 'rb') as _in:\n",
    "with open(\"Шифман Илья. Александр Македонский.txt\", 'rb') as _in:\n",
    "    lines = []\n",
    "    for line in _in:\n",
    "#         line = line.strip().lower().decode(\"ascii\", \"ignore\")\n",
    "        line = line.strip().lower().decode(\"Windows-1251\", \"strict\")\n",
    "        if len(line) == 0:\n",
    "            continue\n",
    "        lines.append(line)\n",
    "text = \" \".join(lines)\n",
    "chars = set([c for c in text])\n",
    "nb_chars = len(chars)\n",
    "\n",
    "\n",
    "# создание индекса символов и reverse mapping чтобы передвигаться между значениями numerical\n",
    "# ID and a specific character. The numerical ID will correspond to a column\n",
    "# ID и определенный символ. Numerical ID будет соответсвовать колонке\n",
    "# число при использовании one-hot кодировки для представление входов символов\n",
    "char2index = {c: i for i, c in enumerate(chars)}\n",
    "index2char = {i: c for i, c in enumerate(chars)}\n",
    "\n",
    "# для удобства выберете фиксированную длину последовательность 10 символов \n",
    "SEQLEN, STEP = 10, 1\n",
    "input_chars, label_chars = [], []\n",
    "\n",
    "# конвертация data в серии разных SEQLEN-length субпоследовательностей\n",
    "for i in range(0, len(text) - SEQLEN, STEP):\n",
    "    input_chars.append(text[i: i + SEQLEN])\n",
    "    label_chars.append(text[i + SEQLEN])\n",
    "\n",
    "\n",
    "# Вычисление one-hot encoding входных последовательностей X и следующего символа (the label) y\n",
    "\n",
    "X = np.zeros((len(input_chars), SEQLEN, nb_chars), dtype=np.bool)\n",
    "y = np.zeros((len(input_chars), nb_chars), dtype=np.bool)\n",
    "for i, input_char in enumerate(input_chars):\n",
    "    for j, ch in enumerate(input_char):\n",
    "        X[i, j, char2index[ch]] = 1\n",
    "    y[i, char2index[label_chars[i]]] = 1\n",
    "\n",
    "\n",
    "# установка ряда метапамертров  для нейронной сети и процесса тренировки\n",
    "BATCH_SIZE, HIDDEN_SIZE = 128, 128\n",
    "NUM_ITERATIONS = 25 # 25 должно быть достаточно\n",
    "NUM_EPOCHS_PER_ITERATION = 3\n",
    "NUM_PREDS_PER_EPOCH = 200\n",
    "\n",
    "\n",
    "# Create a super simple recurrent neural network. There is one recurrent\n",
    "# layer that produces an embedding of size HIDDEN_SIZE from the one-hot\n",
    "# encoded input layer. This is followed by a Dense fully-connected layer\n",
    "# across the set of possible next characters, which is converted to a\n",
    "# probability score via a standard softmax activation with a multi-class\n",
    "# cross-entropy loss function linking the prediction to the one-hot\n",
    "# encoding character label.\n",
    "\n",
    "'''\n",
    "Создание очень простой рекуррентной нейронной сети. В ней будет один реккурентный закодированный входной слой. \n",
    "За ним последует полносвязный слой связанный с набором возможных следующих символов, которые конвертированы \n",
    "в вероятностные результаты через стандартную softmax активацию с multi-class cross-encoding loss функцию ссылающуются \n",
    "на предсказание one-hot encoding лейбл символа\n",
    "'''\n",
    "\n",
    "model = Sequential()\n",
    "model.add(\n",
    "    LSTM(  # вы можете изменить эту часть на GRU, LSTM или SimpleRNN, чтобы попробовать альтернативы\n",
    "        HIDDEN_SIZE,\n",
    "        return_sequences=False,\n",
    "        input_shape=(SEQLEN, nb_chars),\n",
    "        unroll=True\n",
    "    )\n",
    ")\n",
    "model.add(Dense(nb_chars))\n",
    "model.add(Activation(\"softmax\"))\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\")\n",
    "\n",
    "\n",
    "# выполнение серий тренировочных и демонстрационных итераций \n",
    "for iteration in range(NUM_ITERATIONS):\n",
    "\n",
    "    # для каждой итерации запуск передачи данных в модель \n",
    "    print(\"=\" * 50)\n",
    "    print(\"Итерация #: %d\" % (iteration))\n",
    "    model.fit(X, y, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS_PER_ITERATION)\n",
    "\n",
    "    # Select a random example input sequence.\n",
    "    test_idx = np.random.randint(len(input_chars))\n",
    "    test_chars = input_chars[test_idx]\n",
    "\n",
    "    # для числа шагов предсказаний использование текущей тренируемой модели \n",
    "    # конструирование one-hot encoding для тестирования input и добавление предсказания.\n",
    "    print(\"Генерация из посева: %s\" % (test_chars))\n",
    "    print(test_chars, end=\"\")\n",
    "    for i in range(NUM_PREDS_PER_EPOCH):\n",
    "\n",
    "        # здесь one-hot encoding.\n",
    "        X_test = np.zeros((1, SEQLEN, nb_chars))\n",
    "        for j, ch in enumerate(test_chars):\n",
    "            X_test[0, j, char2index[ch]] = 1\n",
    "\n",
    "        # осуществление предсказания с помощью текущей модели.\n",
    "        pred = model.predict(X_test, verbose=0)[0]\n",
    "        y_pred = index2char[np.argmax(pred)]\n",
    "\n",
    "        # вывод предсказания добавленного к тестовому примеру \n",
    "        print(y_pred, end=\"\")\n",
    "\n",
    "        # инкрементация тестового примера содержащего предсказание\n",
    "        test_chars = test_chars[1:] + y_pred\n",
    "print()\n",
    "# print('line', line)\n",
    "# print('lines', lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### В качестве тренировочного текста скачал книгу Ильи Шифмана \"Александр Македонский\"\n",
    "#### При смене параметра GRU на LSTM немного улучшилось качество сгенерированного текста \n",
    "#### При смене оптимайзера с rmsprop на adam не заметил изменений\n",
    "#### При смене функции потерь на mean_squared_error и binary_crossentropy не заметил изменений\n",
    "#### Не могу понять как генерируются слова, которых нет в изначальном тексте"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Практическое задание\n",
    "\n",
    "<ol>\n",
    "    <li>Попробуйте изменить параметры нейронной сети работающей с датасетом imdb либо нейронной сети работающей airline-passengers(она прилагается вместе с датасетом к уроку в виде отдельного скрипта) так, чтобы улучшить ее точность. Приложите анализ.</li>\n",
    "    <li>Попробуйте изменить параметры нейронной сети генерирующий текст таким образом, чтобы добиться генерации как можно более осмысленного текста. Пришлите лучший получившейся у вас текст и опишите, что вы предприняли, чтобы его получить. Можно использовать текст другого прозведения.</li>\n",
    "    <li>* Попробуйте на numpy реализовать нейронную сеть архитектуры LSTM</li>\n",
    "    <li>* Предложите свои варианты решения проблемы исчезающего градиента в RNN</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Дополнительные материалы\n",
    "\n",
    "<ol>\n",
    "    <li>Оригинальная научная статья по LSTM - https://www.bioinf.jku.at/publications/older/2604.pdf</li>\n",
    "    <li>Оригинальная научная статья по GRU - https://arxiv.org/abs/1406.1078</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Используемая литература \n",
    "\n",
    "Для подготовки данного методического пособия были использованы следующие ресурсы:\n",
    "<ol>\n",
    "    <li>https://www.kaggle.com/thebrownviking20/intro-to-recurrent-neural-networks-lstm-gru</li>\n",
    "    <li>Шакла Н. — Машинное обучение и TensorFlow 2019</li>\n",
    "    <li>Николенко, Кадурин, Архангельская: Глубокое обучение. Погружение в мир нейронных сетей 2018</li>\n",
    "    <li>Aurélien Géron - Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems 2019</li>\n",
    "    <li>https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21</li>\n",
    "    <li>https://github.com/llSourcell/recurrent_neural_net_demo</li>\n",
    "    \n",
    "</ol>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
